# Unified Training Configuration for Sequential Decision-Making Modules

# Data
buffer_path: "data/buffer_10.pt"  # Path to replay buffer file (use dummy data if not found)

# State Encoder (Shared across all modules)
encoder_type: "vit"   # Options: "mlp", "cnn", "vit"
latent_dim: 128
use_pretrained_encoder: false  # Set to true to load pretrained encoder from best_model_autoencoder.pth
pretrained_encoder_path: "best_model_autoencoder.pth"  # Path to pretrained autoencoder checkpoint
freeze_pretrained_encoder: false  # Set to true to freeze pretrained encoder parameters
num_arc_colors: 12  # Number of colors in the arc (used for color prediction)

encoder_params:
  depth: 4
  heads: 16
  mlp_dim: 512
  transformer_dim: 64
  pool: "cls"
  dropout: 0.2
  emb_dropout: 0.2
  input_channels: 1
  image_size: [10, 10]
  scaled_position_embeddings: false
  colors_vocab_size: 12 

action_embedders:
  # Action Embedding for Color Selection
  action_color_embedder:
    num_actions: 23  # Set this to the number of color selection functions in DSL
    embed_dim: 32  # Dimension of the action embedding
    dropout_p: 0.2

  # Action Embedding for Selection Functions
  action_selection_embedder:
    num_actions: 6  # Set this to the number of selection functions in DSL
    embed_dim: 32  # Dimension of the action embedding
    dropout_p: 0.2

  # Action Embedding for Transform Functions
  action_transform_embedder:
    num_actions: 18  # Set this to the number of transform actions in DSL
    embed_dim: 32  # Dimension of the action embedding
    dropout_p: 0.2


# Color Predictor Module
color_predictor:
  hidden_dim: 512 #NOTE: this should be the same as the state encoder hidden dim for attention

# Selection Mask Prediction Module
selection_mask:
  latent_mask_dim: 64
  mask_encoder_params:
    vit:
      depth: 2
      heads: 2
      mlp_dim: 64
      pool: "cls"
      dropout: 0.1
      emb_dropout: 0.1
      patch_size: 2
      input_channels: 1
      image_size: [10, 10]
      vocab_size: 12
  # Transformer parameters for selection mask predictor
  transformer_depth: 2
  transformer_heads: 2
  transformer_dim_head: 32
  transformer_mlp_dim: 64
  transformer_dropout: 0.1
  loss_type: "mse"  # Options: "mse", "vicreg"
  use_vicreg: false
  vicreg_sim_coeff: 25.0
  vicreg_std_coeff: 25.0
  vicreg_cov_coeff: 1.0

# Next State Predictor Module
next_state:
  latent_mask_dim: 0  # Set to 0 if not using mask, else specify mask latent dim
  transformer_depth: 2
  transformer_heads: 2
  transformer_dim_head: 64
  transformer_mlp_dim: 128
  transformer_dropout: 0.1
  loss_type: "mse"  # Options: "mse", "vicreg"
  use_vicreg: false
  vicreg_sim_coeff: 25.0
  vicreg_std_coeff: 25.0
  vicreg_cov_coeff: 1.0

# Reward Predictor Module (Transformer-based)
reward_predictor:
  latent_dim: 128  # Dimension of latent vectors (z_t, z_{t+1})
  hidden_dim: 128  # Hidden dimension for transformer
  transformer_depth: 2
  transformer_heads: 2
  transformer_dim_head: 64
  transformer_mlp_dim: 128
  transformer_dropout: 0.1
  proj_dim: null  # If provided, project latents to this dim

# Continuation Predictor Module (Transformer-based)
continuation_predictor:
  latent_dim: 128  # Dimension of latent vectors (z_t, z_{t+1})
  hidden_dim: 128  # Hidden dimension for transformer
  transformer_depth: 2
  transformer_heads: 2
  transformer_dim_head: 64
  transformer_mlp_dim: 128
  transformer_dropout: 0.1
  proj_dim: null  # If provided, project latents to this dim

# Training (Shared across all modules)
batch_size: 32
num_epochs: 50
learning_rate: 0.0003
num_workers: 0
log_interval: 10

# Early Stopping and Model Saving
color_predictor_training:
  early_stopping_patience: 3
  best_model_save_path: "best_model_color_predictor.pth"
selection_predictor_training:
  early_stopping_patience: 3
  best_model_save_path: "best_model_selection_predictor.pth"
next_state_predictor_training:
  early_stopping_patience: 3
  best_model_save_path: "best_model_next_state_predictor.pth"
full_model_training:
  early_stopping_patience: 3
  best_model_save_path: "best_model_full_model.pth"

# Add this to your config.yaml file
early_stopping:
  patience: 4                          # Epochs to wait for improvement
  min_delta: 0.001                     # Minimum improvement threshold (1e-5)
  restore_best_weights: true           # Restore best weights after training
  monitor_metric: "val_loss"           # Metric to monitor ("val_loss" or "val_acc")
  mode: "min"                          # "min" for loss, "max" for accuracy
  min_epochs: 10                       # Minimum epochs before early stopping can trigger
  max_epochs_without_improvement: 30   # Hard stop after this many epochs
  use_adaptive_patience: false         # Whether to use adaptive patience 