# Unified Training Configuration for Sequential Decision-Making Modules

# Data
buffer_path: "buffer.pkl"  # Path to replay buffer file (use dummy data if not found)

# State Encoder (Shared across all modules)
encoder_type: "mlp"  # Options: "mlp", "cnn", "vit"
latent_dim: 128
encoder_params:
  mlp:
    num_hidden_layers: 2
    hidden_dim: 256
    activation_fn_str: "relu"
    dropout_rate: 0.1
    input_channels: 1
    image_size: [10, 10]
  cnn:
    num_conv_layers: 3
    base_filters: 32
    kernel_size: 3
    stride: 2
    padding: 1
    activation_fn_str: "relu"
    fc_hidden_dim: null
    dropout_rate: 0.2
    input_channels: 1
    image_size: [10, 10]
  vit:
    depth: 4
    heads: 2
    mlp_dim: 128
    pool: "cls"
    dropout: 0.1
    emb_dropout: 0.1
    patch_size: 2
    input_channels: 1
    image_size: [10, 10]

# Color Selection Functions
num_color_selection_fns: 19  # Set this to the number of color selection functions in DSL
num_arc_colors: 9

# Selection Functions
num_selection_fns: 8  # Set this to the number of selection functions in DSL

# Transform Functions
num_transform_actions: 8  # Set this to the number of transform actions in DSL

# Color Predictor Module
color_predictor:
  hidden_dim: 128

# Selection Mask Prediction Module
selection_mask:
  mask_encoder_type: "mlp"  # Options: "mlp", "cnn", "vit"
  latent_mask_dim: 64
  mask_encoder_params:
    mlp:
      num_hidden_layers: 2
      hidden_dim: 128
      activation_fn_str: "relu"
      dropout_rate: 0.1
      input_channels: 1
      image_size: [10, 10]
    cnn:
      num_conv_layers: 2
      base_filters: 16
      kernel_size: 3
      stride: 2
      padding: 1
      activation_fn_str: "relu"
      fc_hidden_dim: null
      dropout_rate: 0.1
      input_channels: 1
      image_size: [10, 10]
    vit:
      depth: 2
      heads: 2
      mlp_dim: 64
      pool: "cls"
      dropout: 0.1
      emb_dropout: 0.1
      patch_size: 2
      input_channels: 1
      image_size: [10, 10]
  selection_mask_predictor_hidden_dim: 128
  use_transformer: false
  transformer_depth: 2
  transformer_heads: 2
  transformer_dim_head: 32
  transformer_mlp_dim: 64
  transformer_dropout: 0.1
  loss_type: "mse"  # Options: "mse", "vicreg"
  use_vicreg: false
  vicreg_sim_coeff: 25.0
  vicreg_std_coeff: 25.0
  vicreg_cov_coeff: 1.0

# Next State Predictor Module
next_state:
  latent_mask_dim: 0  # Set to 0 if not using mask, else specify mask latent dim
  transformer_depth: 2
  transformer_heads: 2
  transformer_dim_head: 64
  transformer_mlp_dim: 128
  transformer_dropout: 0.1
  loss_type: "mse"  # Options: "mse", "vicreg"
  use_vicreg: false
  vicreg_sim_coeff: 25.0
  vicreg_std_coeff: 25.0
  vicreg_cov_coeff: 1.0

# Training (Shared across all modules)
batch_size: 32
num_epochs: 10
learning_rate: 0.001
num_workers: 1
log_interval: 10 